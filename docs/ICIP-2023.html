<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>ICIP-2023</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="ICIP-2023_files/libs/clipboard/clipboard.min.js"></script>
<script src="ICIP-2023_files/libs/quarto-html/quarto.js"></script>
<script src="ICIP-2023_files/libs/quarto-html/popper.min.js"></script>
<script src="ICIP-2023_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="ICIP-2023_files/libs/quarto-html/anchor.min.js"></script>
<link href="ICIP-2023_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="ICIP-2023_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="ICIP-2023_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="ICIP-2023_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="ICIP-2023_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">ICIP-2023</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="privacy-attacks-in-computer-vision" class="level2">
<h2 class="anchored" data-anchor-id="privacy-attacks-in-computer-vision">Privacy attacks in computer vision</h2>
<p><strong>Duration</strong>: Half-Day Workshop</p>
<section id="prensenters" class="level3">
<h3 class="anchored" data-anchor-id="prensenters">Prensenters</h3>
<ul>
<li><em>Gianmarco Aversano</em> (<a href="http://euranova.eu/">Euranova</a>, gianmarco.aversano@euranova.eu) is a Data Scientist in Euranova’s Research Department. During his doctorate, he worked at CentraleSupélec Paris, University of Utah, and Université Libre de Bruxelles (ULB). His professional experience focuses on machine learning with a background in data engineering and MLOps, with both the knowledge gained from research and the knowledge acquired in the industrial field. Currently, Gianmarco Aversano contributes to the BISHOP program (https://research.euranova.eu/bishop/) which focuses on graph data generation and privacy risk assessment and mitigation. Besides, Euranova has experience in computer vision [see this publication where I personally contributed and also here] and is also contributing to this field in an upcoming scientific submission in the domain of privacy assessment for generative models of graph data.</li>
<li><em>Yixi Xu</em> (Microsoft, yixi.xu@microsoft.com) is a senior applied research scientist at Microsoft AI for Good Lab mainly focusing on AI for health including its privacy risk estimation. Yixi Xu has a very relevant scientific publication in the domain of privacy assessment for generative models: <a href="https://arxiv.org/pdf/2009.05683.pdf">MACE</a>. In their paper, the authors run experiments on dataset from the computer vision community.</li>
<li><em>Sabri Shkiri</em> (<a href="http://euranova.eu/">Euranova</a>, sabri.shkiri@euranova.eu) leads the Euranova R&amp;D department and managse internal research projects, back office R&amp;D requests, technological watch for customers, technical assessments and innovation forum within Euranova. Sabri Shkiri has been: program Committee member of the IEEE Big Data conference 2023, 2022, &amp; 2021 and of the Stream Reasoning workshop 2021; program committee member of the EAI Mobicase 2022 conference; program co-chair of the Industrial track of ECML PKDD 2021 and DEBS 2021; PC member of DEBS industrial track 2023&amp; 2022; program co-chair of the Workshop on real-time &amp; stream analytics in Big Data, colocated with the IEEE Big Data since 2016; keynote speaker at WETICE 2021, speaker at the industrial keynote of ICML 2020, ICSOC 2019, Worldwide AI Show Dubai 2019, myData 2017, ICT Spring 2017, HPS Powercard 2015, Big Data Technologies China 2014, Huawei Strategy &amp; Technology Workshop 2012 &amp; 2014, EBISS 2012, ECLIPSE CON 2009 &amp; 2013, IBM GSE 2012, FOSDEM 2010; member of the Jury for FRIA PhD Scholarship of the FNRS from 2021 to 2023.</li>
</ul>
</section>
<section id="description" class="level3">
<h3 class="anchored" data-anchor-id="description">Description</h3>
<p>Machine Learning models are vulnerable to privacy attacks, and computer vision (CV) models are no exception to this. This means that simply publishing a pretrained image classifier or generator opens the door to attacks such as Membership Inference (MI), which aims to predict if a target image was part of the training set. Understanding why privacy attacks are possible and how to prevent them is crucial towards the objective of building Responsible AI tools.</p>
<p>In this workshop, we will cover the subject of privacy attacks in CV by introducing:</p>
<ol type="1">
<li><p>Privacy in Machine Learning: what is it?</p></li>
<li><p>The main Privacy Attacks against Machine Learning models</p></li>
<li><p>How to defend Machine Learning models from Privacy Attacks</p></li>
<li><p>Privacy vs Utility: optimizing the privacy-utility trade-off</p></li>
<li><p>Privacy Auditing: how to estimate any privacy risk in advance?</p></li>
<li><p>Invited speakers</p></li>
<li><p>Hands-on sessions</p></li>
</ol>
<p>We will also show practical examples using open-source libraries. Finally, we will also put extra focus on the synthetic image generators, which have been gaining momentum recently, and which we fear may be used wrongly.</p>
<p>We believe this workshop can be relevant for the following reasons:</p>
<ul>
<li>make the CV community aware of the privacy-utility trade-off that also exists in the image domain;</li>
<li>provide CV practitioners with the theoretical and practical tools that are needed to estimate the privacy-utility trade-off in their use-case;</li>
<li>given the increasing popularity of image generative models, this workshop can provide model-agnostic fundamentals on how to assess the privacy leakage of such models and the images they generate in a robust manner.</li>
</ul>
<p>This workshop will be composed of keynote sessions on the theoretical background, keynote sessions for invited speakers whose papers have been accepted by this workshop, and one session on practical use-cases. The workshop will be held by Euranova’s R&amp;D department.</p>
</section>
<section id="call-for-papers" class="level3">
<h3 class="anchored" data-anchor-id="call-for-papers">Call for Papers</h3>
<!-- For Call for papers, you'd want to provide some info. on the focus area of the workshop, topics of interest, submission deadline, notification deadline, paper formatting requirements (can link to the ICIP one as the instructions should be similar). -->
<p>Authors are invited to submit full-length papers (up to 4 pages for technical content including figures and references, and one optional 5th page containing only references). Submission instructions, templates for paper format, and the “no show” policy are available at the conference website <a href="https://2023.ieeeicip.org/privacy-and-non-discrimination-statements/">here</a>. All accepted papers will be published in IEEE Xplore.</p>
<p>We accept papers contributing to the following domains:</p>
<ul>
<li>Membership Inference attacks on images against unsupervised learning;</li>
<li>Membership Inference attacks on images against supervised learning;</li>
<li>Membership Inference attacks on images against image generative models;</li>
<li>Defense mechanisms against Membership Inference attacks on images;</li>
<li>Privacy Auditung and Membership Privacy Estimation in image generative models;</li>
</ul>
<p>To submit your paper, …</p>
<section id="deadline" class="level4">
<h4 class="anchored" data-anchor-id="deadline">Deadline</h4>
<p>The deadline for submissions is 15 July 2023 at midnight GTM +2.</p>
</section>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>